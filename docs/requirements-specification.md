# mem0 기반 LTM(Long-Term Memory) 시스템 요구사항 명세서

## 📋 프로젝트 개요

mem0를 활용한 지속적인 대화 컨텍스트 관리 시스템으로, 사용자별 장기 기억을 효율적으로 저장하고 검색하여 대화 맥락에 따라 관련 기억을 자동으로 활용하는 웹 기반 서비스

## 1. 핵심 목표

- mem0를 활용한 지속적인 대화 컨텍스트 관리 시스템 구축
- 사용자별 장기 기억을 효율적으로 저장하고 검색
- 대화 맥락에 따라 관련 기억을 자동으로 활용
- 사용자가 수동으로 입력한 메모리를 자동 분류 및 최적화

## 2. 기술 스택

```
- Memory Management: mem0
- LLM: Ollama (로컬 모델 - llama2, mistral, qwen 등)
- Vector DB: Qdrant/ChromaDB (로컬 실행 가능)
- Backend: FastAPI/Flask
- Frontend: React/Vue.js 또는 Streamlit/Gradio
- Database: SQLite/PostgreSQL (메타데이터용)
```

## 3. 핵심 기능 요구사항

### 3.1 메모리 관리

#### 자동 메모리 관리
- **사용자별 메모리 분리**: 각 사용자의 대화 기록과 컨텍스트 독립 관리
- **메모리 계층 구조**:
  - Short-term: 현재 대화 세션
  - Long-term: 과거 대화에서 추출된 중요 정보
  - Episodic: 특정 이벤트나 대화 에피소드
- **자동 메모리 추출**: 대화에서 중요 정보 자동 식별 및 저장
- **메모리 업데이트**: 기존 정보 수정/보강 메커니즘

#### 수동 메모리 입력 및 자동 분류
- **다양한 입력 방식**:
  - 대량 입력 모드: CSV/JSON 파일 업로드
  - 개별 입력 모드: 폼 기반 입력
  - 텍스트 덤프: 자유 형식 텍스트에서 정보 추출
  - 노트 임포트: Notion, Obsidian, Roam Research 등에서 가져오기

### 3.2 자동 분류 시스템

#### 카테고리 자동 분류
```python
categories = {
    "personal_info": ["이름", "나이", "생일", "주소", "연락처"],
    "preferences": ["좋아하는", "싫어하는", "선호", "취향"],
    "experiences": ["여행", "경험", "추억", "사건"],
    "knowledge": ["학습", "지식", "정보", "팁"],
    "relationships": ["가족", "친구", "동료", "관계"],
    "goals": ["목표", "계획", "희망", "꿈"],
    "health": ["건강", "운동", "식단", "질병"],
    "work": ["직장", "업무", "프로젝트", "경력"]
}
```

#### 메타데이터 자동 추출
- **시간 정보**: 날짜, 기간, 빈도 자동 파싱
- **장소 정보**: 지역명, 장소 자동 인식
- **인물 정보**: 이름, 관계 자동 태깅
- **감정 정보**: 긍정/부정, 감정 강도 분석
- **중요도**: 컨텍스트 기반 자동 평가

### 3.3 지능형 저장 구조

#### 계층적 메모리 구조
```
Root Memory
├── Core Identity (핵심 정체성)
│   ├── Basic Info (기본 정보)
│   ├── Personality (성격)
│   └── Values (가치관)
├── Episodic Memory (일화 기억)
│   ├── Life Events (인생 사건)
│   ├── Daily Routines (일상)
│   └── Special Moments (특별한 순간)
├── Semantic Memory (의미 기억)
│   ├── Skills (기술)
│   ├── Knowledge (지식)
│   └── Facts (사실)
└── Procedural Memory (절차 기억)
    ├── Habits (습관)
    ├── Preferences (선호)
    └── Methods (방법론)
```

#### 연관 관계 맵핑
- **caused_by**: 인과 관계
- **related_to**: 연관 관계
- **contradicts**: 모순 관계
- **updates**: 업데이트 관계
- **part_of**: 부분-전체 관계

### 3.4 검색 및 활용
- **컨텍스트 기반 검색**: 현재 대화와 관련된 과거 기억 자동 검색
- **유사도 임계값 설정**: 관련성 정도 조절 가능
- **시간 가중치**: 최근 기억에 더 높은 가중치
- **메모리 요약**: 긴 대화 내용을 핵심 포인트로 압축

## 4. 스마트 처리 파이프라인

### 메모리 처리 단계
1. **Input Parsing (입력 파싱)**
   - 텍스트 정규화
   - 언어 감지
   - 구조 분석

2. **Information Extraction (정보 추출)**
   - NER (개체명 인식)
   - 날짜/시간 추출
   - 키워드 추출
   - 감정 분석

3. **Classification (분류)**
   - 카테고리 결정
   - 중요도 평가
   - 신뢰도 점수 계산

4. **Deduplication (중복 제거)**
   - 기존 메모리와 비교
   - 유사도 검사
   - 병합/업데이트 결정

5. **Enrichment (보강)**
   - 컨텍스트 추가
   - 관련 정보 연결
   - 태그 자동 생성

6. **Storage Optimization (저장 최적화)**
   - 압축
   - 인덱싱
   - 캐싱 전략

## 5. Web UI 기능

### 5.1 대화 인터페이스
- 채팅 UI (메시지 입력/표시)
- 현재 활용 중인 메모리 표시
- 대화 히스토리 뷰어

### 5.2 메모리 관리 대시보드
- 저장된 메모리 조회/편집/삭제
- 메모리 통계 (개수, 카테고리, 시간대별 분포)
- 메모리 검색 및 필터링

### 5.3 메모리 입력 대시보드
```
┌─────────────────────────────────────┐
│  📝 메모리 수동 입력                   │
├─────────────────────────────────────┤
│ [텍스트 입력 영역]                     │
│ "오늘 점심에 김치찌개 먹었는데         │
│  너무 매웠지만 맛있었다..."            │
│                                      │
│ [파일 업로드] [음성 입력]             │
├─────────────────────────────────────┤
│ 🤖 AI 분석 결과                      │
│ • 카테고리: 음식 경험                 │
│ • 감정: 긍정적 (만족)                 │
│ • 키워드: #김치찌개 #매운음식 #점심    │
│ • 관련 기억: "한식 선호" 연결됨        │
├─────────────────────────────────────┤
│ [저장] [수정] [다시 분석]             │
└─────────────────────────────────────┘
```

### 5.4 일괄 처리 인터페이스
- **템플릿 제공**: 일기, 여행기록, 학습노트 등
- **가이드 모드**: 질문 형식으로 메모리 수집
- **음성 메모**: STT로 음성 기록 텍스트 변환
- **이미지 메모**: OCR로 이미지의 텍스트 추출

### 5.5 사용자 관리
- 로그인/로그아웃
- 프로필별 메모리 분리
- 메모리 내보내기/가져오기

## 6. 성능 요구사항

### 6.1 응답 성능
- **응답 시간**: 메모리 검색 포함 3초 이내 응답
- **메모리 용량**: 사용자당 최소 10,000개 메모리 항목 지원
- **동시 사용자**: 5-10명 동시 접속 지원 (로컬 환경)
- **메모리 정확도**: 관련 메모리 검색 정확도 80% 이상

### 6.2 분류 성능
- **정확도**: 90% 이상 올바른 카테고리 분류
- **처리 속도**: 1000자 텍스트 1초 이내 처리
- **중복 감지율**: 95% 이상 중복 메모리 식별

### 6.3 저장 효율성
- **압축률**: 원본 대비 70% 용량 절감
- **검색 속도**: 10만 개 메모리에서 100ms 이내 검색
- **관계 매핑**: 평균 3-5개 연관 메모리 자동 연결

## 7. 테스트 시나리오

### 7.1 기본 기능 테스트
```python
# 예시 테스트 케이스
1. 사용자 정보 저장
   - "내 이름은 홍길동이고 개발자야"
   - 다음 세션에서 "내 직업이 뭐였지?" 질문 시 정확한 답변

2. 선호도 기억
   - "나는 파이썬을 좋아하고 자바는 싫어해"
   - 이후 프로그래밍 추천 시 파이썬 위주 추천

3. 대화 맥락 유지
   - 프로젝트 관련 긴 대화 진행
   - 며칠 후 "지난번 프로젝트 얘기 이어서 하자" 시 컨텍스트 복원
```

### 7.2 수동 입력 테스트

#### 단순 입력 테스트
```python
# 입력
"피자보다 치킨을 더 좋아함"

# 예상 결과
{
    "category": "preferences",
    "subcategory": "food",
    "entities": ["피자", "치킨"],
    "preference_type": "comparison",
    "strength": "strong"
}
```

#### 복잡한 입력 테스트
```python
# 입력
"2020년 여름에 부산 해운대에서 대학 동창들과 만났는데,
그때 처음으로 서핑을 배웠다. 김철수가 가르쳐줬는데
너무 어려웠지만 재미있어서 또 하고 싶다."

# 예상 결과
{
    "category": "experiences",
    "date": "2020년 여름",
    "location": "부산 해운대",
    "people": ["김철수", "대학 동창들"],
    "activity": "서핑",
    "emotion": "긍정적",
    "first_time": true,
    "want_repeat": true,
    "relationships": [
        {"person": "김철수", "role": "instructor"},
        {"group": "대학 동창들", "context": "reunion"}
    ]
}
```

### 7.3 복잡한 시나리오
- **정보 업데이트**: "아 맞다, 내가 지난번에 말한 것 수정할게..."
- **모순 해결**: 상충되는 정보 처리
- **시간 기반 검색**: "작년에 얘기했던 그 프로젝트..."
- **다중 주제**: 여러 주제를 오가며 대화

## 8. 개발 단계

### Phase 0: 자동 분류 시스템 (1주)
- NLP 파이프라인 구축
- 분류 모델 훈련
- 메타데이터 추출기 개발

### Phase 1: 기본 구조 (1-2주)
- Ollama 설정 및 모델 선택
- mem0 초기 설정
- 벡터 DB 구축
- 기본 API 엔드포인트

### Phase 2: 메모리 시스템 (3-4주)
- 메모리 저장/검색 로직
- 컨텍스트 관리자 구현
- 메모리 품질 평가 메트릭
- 수동 입력 통합
- 지능형 분류 엔진
- 중복 제거 및 병합 로직
- 관계 맵핑 시스템

### Phase 3: Web UI (2-3주)
- 채팅 인터페이스
- 메모리 대시보드
- 메모리 입력 대시보드
- 사용자 인증

### Phase 4: 최적화 및 테스트 (1-2주)
- 성능 튜닝
- 엣지 케이스 처리
- 사용성 개선

## 9. 추가 고려사항

### 9.1 보안 및 프라이버시
- **프라이버시**: 로컬 실행으로 데이터 보안
- **암호화**: 저장된 메모리 암호화
- **접근 제어**: 사용자별 인증 및 권한 관리

### 9.2 확장성
- **백업**: 메모리 데이터 정기 백업
- **확장성**: 클라우드 마이그레이션 가능한 구조
- **API 설계**: RESTful API로 외부 연동 가능

### 9.3 모니터링
- **성능 모니터링**: 메모리 사용량, 검색 성능 추적
- **사용 분석**: 사용자 행동 패턴 분석
- **오류 추적**: 자동 오류 보고 및 로깅

### 9.4 학습 메커니즘
- **사용자 피드백**: 분류 정확도 개선
- **개인화**: 사용자별 선호 패턴 학습
- **모델 업데이트**: 주기적 모델 재훈련

## 10. 기대 효과

- 사용자의 모든 중요 정보를 체계적으로 관리
- AI와의 대화에서 개인화된 경험 제공
- 장기간에 걸친 일관된 컨텍스트 유지
- 효율적인 지식 관리 및 검색